{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook enables training and testing of Sherlock.\n",
    "The procedure is:\n",
    "- Load train, val, test datasets (should be preprocessed)\n",
    "- Initialize model using the \"pretrained\" model or by training one from scratch.\n",
    "- Evaluate and analyse the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the ID for the retrained model,\n",
    "#further down predictions can also be made with the original model: \"sherlock\"\n",
    "model_id = 'retrained_sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sherlock.deploy.model import SherlockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets for training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-04-20 16:20:00.808649\n",
      "(412059, 1588)\n",
      "Load data (train) process took 0:00:12.494049 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1882/1291335495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Started at {start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/data/processed/validation.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/data/raw/val_labels.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-04-06 09:54:52.079637\n",
      "Finished at 2022-04-06 09:54:55.915934, took 0:00:03.836310 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_entropy', 'frac_unique', 'frac_numcells', 'frac_textcells', 'avg_num_cells', 'std_num_cells', 'avg_text_cells', 'std_text_cells', 'avg_spec_cells', 'std_spec_cells', 'avg_word_cells', 'std_word_cells', 'n_values', 'length-agg-any', 'length-agg-all', 'length-agg-mean', 'length-agg-var', 'length-agg-min', 'length-agg-max', 'length-agg-median', 'length-agg-sum', 'length-agg-kurtosis', 'length-agg-skewness', 'none-agg-has', 'none-agg-percent', 'none-agg-num', 'none-agg-all']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sherlock.deploy import helpers\n",
    "\n",
    "feature_cols = helpers.categorize_features()\n",
    "print(feature_cols[\"rest\"]) # char / word / par / rest\n",
    "\n",
    "#X_train[['par_vec_0', 'par_vec_1']]\n",
    "X_train_char = X_train[feature_cols[\"char\"]]\n",
    "X_train_char.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "Two options:\n",
    "- Load Sherlock model with pretrained weights\n",
    "- Fit Sherlock model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: load Sherlock with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-04-06 09:54:55.919779\n",
      "WARNING:tensorflow:From /home/sunny/miniconda3/envs/env5/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/sunny/miniconda3/envs/env5/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/sunny/miniconda3/envs/env5/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/sunny/miniconda3/envs/env5/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 09:54:56.329225: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 09:54:56.381408: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 4001000000 Hz\n",
      "2022-04-06 09:54:56.383827: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffc9554520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-06 09:54:56.383907: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "OMP: Info #155: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #217: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #217: KMP_AFFINITY: x2APIC ids not unique.\n",
      "OMP: Info #217: KMP_AFFINITY: decoding legacy APIC ids.\n",
      "OMP: Info #217: KMP_AFFINITY: legacy APIC ids not unique.\n",
      "OMP: Info #221: KMP_AFFINITY: parsing /proc/cpuinfo.\n",
      "OMP: Info #157: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #158: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #288: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "OMP: Info #192: KMP_AFFINITY: 1 socket x 4 cores/socket x 2 threads/core (4 total cores)\n",
      "OMP: Info #219: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 1 maps to socket 0 core 0 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 2 maps to socket 0 core 1 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 3 maps to socket 0 core 1 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 4 maps to socket 0 core 2 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 5 maps to socket 0 core 2 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 6 maps to socket 0 core 3 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 7 maps to socket 0 core 3 thread 1 \n",
      "OMP: Info #255: KMP_AFFINITY: pid 15520 tid 15520 thread 0 bound to OS proc set 0\n",
      "2022-04-06 09:54:56.386831: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model.\n",
      "Finished at 2022-04-06 09:54:56.828820, took 0:00:00.909051 seconds\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "model = SherlockModel();\n",
    "model.initialize_model_from_json(with_weights=True, model_id=\"sherlock\");\n",
    "\n",
    "print('Initialized model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: fit Sherlock from scratch (and save for later use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"retrained_sherlock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-04-04 15:22:51.043972\n",
      "Train on 412059 samples, validate on 137353 samples\n",
      "Epoch 1/2\n",
      "412059/412059 [==============================] - 63s 153us/sample - loss: 1.6248 - categorical_accuracy: 0.6946 - val_loss: 1.0363 - val_categorical_accuracy: 0.8277\n",
      "Epoch 2/2\n",
      "412059/412059 [==============================] - 58s 141us/sample - loss: 0.9634 - categorical_accuracy: 0.8360 - val_loss: 0.9409 - val_categorical_accuracy: 0.8494\n",
      "Trained and saved new model.\n",
      "Finished at 2022-04-04 15:24:59.291637, took 0:02:08.247681 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "model = SherlockModel()\n",
    "# Model will be stored with ID `model_id`\n",
    "model.fit(X_train, y_train, X_validation, y_validation, model_id=model_id)\n",
    "\n",
    "print('Trained and saved new model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.store_weights(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model.to_json2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = SherlockModel();\n",
    "st = model.initialize_model_from_json(with_weights=True, model_id=\"retrained_sherlock\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "predicted_labels = np.array([x.lower() for x in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "size=len(y_test)\n",
    "\n",
    "# Should be fully deterministic too.\n",
    "f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the original model, model_id should be replaced with \"sherlock\"\n",
    "#model_id = \"sherlock\"\n",
    "classes = np.load(f\"../model_files/classes_{model_id}.npy\", allow_pickle=True)\n",
    "\n",
    "report = classification_report(y_test, predicted_labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[0:5]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[len(class_scores)-5:len(class_scores)]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = predicted_labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "        \n",
    "        # zoom in to specific errors. Use the index in the next step\n",
    "        if k1 in ('address'):\n",
    "            print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1001\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{predicted_labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envKedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "067fbafb8497a6b213015d42733fcc9edf67b269b0a1726470d212d235a61220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
