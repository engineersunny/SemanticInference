{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2b1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from typing import Any, Callable, Sequence, Optional\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "from sherlock.deploy.model import SherlockModel\n",
    "from sherlock.deploy import helpers\n",
    "import graphviz\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806cc932",
   "metadata": {},
   "source": [
    "## Download & Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af3a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sherlock.features.paragraph_vectors import initialise_pretrained_model, initialise_nltk\n",
    "# from sherlock.features.preprocessing import (\n",
    "#     extract_features,\n",
    "#     convert_string_lists_to_lists,\n",
    "#     prepare_feature_extraction,\n",
    "#     load_parquet_values,\n",
    "# )\n",
    "\n",
    "# from sherlock.features.word_embeddings import initialise_word_embeddings\n",
    "\n",
    "\n",
    "# prepare_feature_extraction()\n",
    "# initialise_word_embeddings()\n",
    "# initialise_pretrained_model(400)\n",
    "# initialise_nltk()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca9577d",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09c4c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data process took 0:00:17.111887 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "#X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "X_validation = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print(f'Load data process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff95873",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Repos/SemanticInference/sherlock/deploy/helpers.py:18: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  feature_cols_dict[feature_set] = pd.read_csv(\n",
      "/mnt/d/Repos/SemanticInference/sherlock/deploy/helpers.py:18: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  feature_cols_dict[feature_set] = pd.read_csv(\n",
      "/mnt/d/Repos/SemanticInference/sherlock/deploy/helpers.py:18: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  feature_cols_dict[feature_set] = pd.read_csv(\n",
      "/mnt/d/Repos/SemanticInference/sherlock/deploy/helpers.py:18: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  feature_cols_dict[feature_set] = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(y_train))\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "\n",
    "feature_cols = helpers.categorize_features()\n",
    "\n",
    "X_train_char = X_train[feature_cols[\"char\"]]\n",
    "X_train_word = X_train[feature_cols[\"word\"]]\n",
    "X_train_par = X_train[feature_cols[\"par\"]]\n",
    "X_train_rest = X_train[feature_cols[\"rest\"]]\n",
    "\n",
    "X_val_char = X_validation[feature_cols[\"char\"]]\n",
    "X_val_word = X_validation[feature_cols[\"word\"]]\n",
    "X_val_par = X_validation[feature_cols[\"par\"]]\n",
    "X_val_rest = X_validation[feature_cols[\"rest\"]]\n",
    "\n",
    "y_train_int = encoder.transform(y_train)   #(412059,)\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train_int) #(412059,78)\n",
    "\n",
    "y_val_int = encoder.transform(y_validation)\n",
    "y_val_cat = tf.keras.utils.to_categorical(y_val_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afa8a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "j_1 = jnp.array(pd.DataFrame(X_train_char).to_numpy())\n",
    "j_2 = jnp.array(pd.DataFrame(X_train_word).to_numpy())\n",
    "j_3 = jnp.array(pd.DataFrame(X_train_par).to_numpy())\n",
    "j_4 = jnp.array(pd.DataFrame(X_train_rest).to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59a7f8",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33df66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestModel(nn.Module):\n",
    "    features: Sequence[int]\n",
    "  \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        x = nn.BatchNorm(use_running_average=True,\n",
    "                 momentum=0.9,\n",
    "                 epsilon=1e-5,\n",
    "                 dtype=jnp.float32)(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f00e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubModel(nn.Module):\n",
    "    features: Sequence[int]\n",
    "    training: bool = True\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        # batchnormalisation - https://github.com/google/flax/issues/932\n",
    "        x = nn.BatchNorm(use_running_average=True,\n",
    "                 momentum=0.9,\n",
    "                 epsilon=1e-5,\n",
    "                 dtype=jnp.float32)(x)\n",
    "        \n",
    "        x = nn.relu(nn.Dense(self.features[0])(x))\n",
    "        \n",
    "        # dropout\n",
    "        x = nn.Dropout(rate=0.35)(x, deterministic=True)\n",
    "                \n",
    "        x = nn.relu(nn.Dense(self.features[1])(x)) \n",
    "        \n",
    "        # todo: add \n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b45c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n",
      "[4146024105  967050713]\n",
      "[0.14389051]\n",
      "[-2.6105583   0.03385283  1.0863333  -1.4802988   0.48895672  1.062516\n",
      "  0.54174834  0.0170228   0.2722685   0.30522448]\n"
     ]
    }
   ],
   "source": [
    "# PRNGKey Example\n",
    "print(random.PRNGKey(0))\n",
    "key1, key2 = random.split(random.PRNGKey(0))\n",
    "print(key1)\n",
    "print(random.normal(key1,shape=(1,)))\n",
    "\n",
    "a = random.normal(key1, (10,))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee3435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    feature_size: int = 500\n",
    "    num_classes: int = 78\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x1, x2, x3, x4):\n",
    "       \n",
    "        # [1] define shape        \n",
    "        y1 = SubModel([300, 300], name='char_model')(x1)      \n",
    "        y2 = SubModel([200, 200], name='word_model')(x2)\n",
    "        y3 = SubModel([400, 400], name='par_model')(x3)\n",
    "        y4 = RestModel([27], name='rest_model')(x4)\n",
    "                      \n",
    "        # [2] concat submodels    \n",
    "        x = jnp.concatenate((y1, y2, y3, y4), axis=-1)\n",
    "        \n",
    "        print(\"check mainmodel shape\")\n",
    "        print(np.shape(x))\n",
    "        \n",
    "        # batchnormalisation\n",
    "        x = nn.BatchNorm(use_running_average=True,\n",
    "                 momentum=0.9,\n",
    "                 epsilon=1e-5,\n",
    "                 dtype=jnp.float32)(x)\n",
    "        \n",
    "        # dense 1\n",
    "        x = nn.relu(nn.Dense(self.feature_size)(x))\n",
    "        \n",
    "        # dropout\n",
    "        x = nn.Dropout(rate=0.35)(x, deterministic=True)\n",
    "        \n",
    "        # dense 2\n",
    "        x = nn.relu(nn.Dense(self.feature_size)(x))\n",
    "        \n",
    "        # dense w/ softmax - todo: check\n",
    "        x = nn.softmax(nn.Dense(self.feature_size)(x), axis=-1)\n",
    "        \n",
    "        return nn.Dense(self.num_classes)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "590cbc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check mainmodel shape\n",
      "(1, 927)\n"
     ]
    }
   ],
   "source": [
    "mainmodel = MainModel()\n",
    "p_main = mainmodel.init(jax.random.PRNGKey(0), jnp.ones((1, 960)), jnp.ones((1, 201)), jnp.ones((1, 400)), jnp.ones((1, 27))) \n",
    "#(1, 927)\n",
    "\n",
    "\n",
    "\n",
    "# ??\n",
    "# it's not actual training part ( training = optax)\n",
    "# should I use jnp.ones((1, 960)) instead of actual data for faster computation\n",
    "\n",
    "\n",
    "#y_main = mainmodel.apply(p_main,j_1,j_2,j_3,j_4)\n",
    "#(412059, 927)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ffb6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozen_dict_keys(['char_model', 'word_model', 'par_model', 'rest_model', 'BatchNorm_0', 'Dense_0', 'Dense_1', 'Dense_2', 'Dense_3'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p_main\n",
    "p_main['params'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9325b0",
   "metadata": {},
   "source": [
    "## Model Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42898abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowered = jax.jit(mainmodel.apply).lower(p_main,j_1,j_2,j_3,j_4)\n",
    "# comp_dot = graphviz.Source(lowered._xla_computation().as_hlo_dot_graph())\n",
    "# comp_dot.render('nn_outcome', view=True).replace('\\\\', '/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b0bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_main.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf381d",
   "metadata": {},
   "source": [
    "## Training - OPTAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f58d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "n_training_steps = 100\n",
    "\n",
    "# Define an MSE loss function.\n",
    "def make_mse_func(x_b_1, x_b_2, x_b_3, x_b_4, y_batched):\n",
    "  def mse(p_main):    \n",
    "    # Define the squared loss for a single (x, y) pair.\n",
    "    def squared_error(x1, x2, x3, x4, y):      \n",
    "      pred = mainmodel.apply(p_main, x1, x2, x3, x4)\n",
    "      return jnp.inner(y-pred, y-pred) / 2.0  \n",
    "    \n",
    "    # Vectorise the squared error and compute the average of the loss.\n",
    "    return jnp.mean(jax.vmap(squared_error)(x_b_1, x_b_2, x_b_3, x_b_4, y_batched), axis=0)\n",
    "  return jax.jit(mse)  # `jit` the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7f41a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Repos/SemanticInference/notebooks/02-1-3-train-with-Flax-Graph-Functional.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/Repos/SemanticInference/notebooks/02-1-3-train-with-Flax-Graph-Functional.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m params \u001b[39m=\u001b[39m p_main\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/Repos/SemanticInference/notebooks/02-1-3-train-with-Flax-Graph-Functional.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#dst_x = jnp.concatenate((j_1, j_2, j_3, j_4), axis=-1)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/Repos/SemanticInference/notebooks/02-1-3-train-with-Flax-Graph-Functional.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m dst_y \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39marray(y_train_cat)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_main' is not defined"
     ]
    }
   ],
   "source": [
    "params = p_main\n",
    "\n",
    "#dst_x = jnp.concatenate((j_1, j_2, j_3, j_4), axis=-1)\n",
    "dst_y = jnp.array(y_train_cat)\n",
    "\n",
    "# Instantiate the sampled loss.\n",
    "loss = make_mse_func(j_1, j_2, j_3, j_4, dst_y)\n",
    "\n",
    "optimizer = optax.adam(learning_rate=learning_rate)\n",
    "\n",
    "# Create optimiser state.\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "# Compute the gradient of the loss function.\n",
    "loss_grad_fn = jax.value_and_grad(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015ad562",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Repos/SemanticInference/notebooks/02-1-3-train-with-Flax-Graph-Functional.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/Repos/SemanticInference/notebooks/02-1-3-train-with-Flax-Graph-Functional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m y_train_cat\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_cat' is not defined"
     ]
    }
   ],
   "source": [
    "y_train_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93bcf92",
   "metadata": {},
   "source": [
    "## Execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22217fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check mainmodel shape\n",
      "(927,)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Minimise the loss.\n",
    "start = datetime.now()\n",
    "\n",
    "for step in range(500):\n",
    "    # Compute gradient of the loss.\n",
    "    loss_val, grads = loss_grad_fn(params)\n",
    "    # Update the optimiser state, create an update to the params.\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    # Update the parameters.\n",
    "    params = optax.apply_updates(params, updates)\n",
    "     \n",
    "    print(f'Loss[{step}] = {loss_val}')\n",
    "        \n",
    "print(f'process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c16c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02866286  0.00391353 -0.01072783 ... -0.03264792  0.00024129\n",
      "  -0.00021848]\n",
      " [ 0.00095735 -0.0189361  -0.02946479 ...  0.04912312 -0.00165965\n",
      "   0.01241112]\n",
      " [ 0.03084684  0.04030455  0.01075094 ... -0.02086708 -0.00404731\n",
      "  -0.06132798]\n",
      " ...\n",
      " [-0.06701497  0.04543946  0.03028561 ... -0.01327508  0.04897631\n",
      "   0.03002343]\n",
      " [ 0.01275493  0.01944453 -0.04737942 ...  0.02383648 -0.04277041\n",
      "   0.06001806]\n",
      " [ 0.02494416 -0.00382685  0.0251975  ...  0.05030839 -0.0230723\n",
      "   0.03849551]]\n",
      "(927, 500)\n"
     ]
    }
   ],
   "source": [
    "#check param\n",
    "print(params[\"params\"][\"Dense_0\"][\"kernel\"])\n",
    "print(params[\"params\"][\"Dense_0\"][\"kernel\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460981f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5b1601d",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_v_1 = jnp.array(pd.DataFrame(X_val_char).to_numpy())\n",
    "j_v_2 = jnp.array(pd.DataFrame(X_val_word).to_numpy())\n",
    "j_v_3 = jnp.array(pd.DataFrame(X_val_par).to_numpy())\n",
    "j_v_4 = jnp.array(pd.DataFrame(X_val_rest).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc34f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137353, 78)\n"
     ]
    }
   ],
   "source": [
    "# print(dst_x.shape) #(412059, 960)\n",
    "y_pred = mainmodel.apply(params, j_v_1, j_v_2, j_v_3, j_v_4)\n",
    "print(y_pred.shape) #(137353, 78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebac1ea0",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7197ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['county' 'genre' 'age' ... 'duration' 'class' 'jockey']\n",
      "(137353,)\n",
      "0.6771786681057324\n",
      "0.7096896318245688\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = helpers._proba_to_classes(y_pred, \"sherlock\")\n",
    "\n",
    "print(y_pred_classes)\n",
    "print(y_pred_classes.shape)\n",
    "\n",
    "print(f1_score(y_validation, y_pred_classes, average=\"weighted\"))\n",
    "print(accuracy_score(y_validation, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55ad0a",
   "metadata": {},
   "source": [
    "## memo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST Submodel | Dropout separate key issue: Don't need to worry about. The aim is passing the same key to drop out same nodes across multiple devices.\n",
    "\n",
    "# Can't use one line here like how it's calling submodel in mainmodel?\n",
    "# https://flax.readthedocs.io/en/latest/flax.errors.html#flax.errors.CallCompactUnboundModuleError\n",
    "# submodel = SubModel([300, 300], name='char_model')(j_1)\n",
    "submodel = SubModel([300, 300], name='char_model')\n",
    "\n",
    "\n",
    "#p_sub = submodel.init(jax.random.PRNGKey(0),jnp.ones((1, 960)))\n",
    "p_sub = submodel.init({'params': jax.random.PRNGKey(0), 'dropout': jax.random.PRNGKey(0)},jnp.ones((1, 960)))\n",
    "y = submodel.apply(p_sub, j_1, rngs={'dropout': jax.random.PRNGKey(0)})\n",
    "\n",
    "p_sub['params'].keys()\n",
    "\n",
    "# Do we need to use separate keys like - key1, key2, key3, key4 = random.split(random.PRNGKey(seed), 4) ?\n",
    "# https://github.com/gordicaleksa/get-started-with-JAX/blob/main/Tutorial_4_Flax_Zero2Hero_Colab.ipynb\n",
    "# https://flax.readthedocs.io/en/latest/_autosummary/flax.linen.Dropout.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(env_jax_3)",
   "language": "python",
   "name": "env_jax_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cad61fa92ecfc1bb6c19adae557b65f7e506175839cef010e2ffca4a04a042f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
