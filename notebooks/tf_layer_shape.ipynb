{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5beff75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3d2b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd9aac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    concatenate,\n",
    ")\n",
    "import tensorflow as tf\n",
    "lamb = 0.0001\n",
    "do = 0.35\n",
    "lr = 0.0001\n",
    "\n",
    "\n",
    "char_shape = 960\n",
    "word_shape = 201\n",
    "par_shape = 400\n",
    "rest_shape = 27\n",
    "\n",
    "\n",
    "\n",
    "n_weights = 300\n",
    "\n",
    "char_model_input = Input(shape=(char_shape,))\n",
    "char_model1 = BatchNormalization(axis=1)(char_model_input)\n",
    "char_model2 = Dense(\n",
    "    n_weights,\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    ")(char_model1)\n",
    "char_model3 = Dropout(do)(char_model2)\n",
    "\n",
    "char_model4 = Dense(\n",
    "    n_weights,\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    ")(char_model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a67140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sherlock.deploy.model import SherlockModel\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "X_val = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_val = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "y_val = np.array([x.lower() for x in y_val])\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeddd4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/GitCode/sherlock-project/sherlock/deploy/helpers.py:18: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  feature_cols_dict[feature_set] = pd.read_csv(\n",
      "/mnt/d/GitCode/sherlock-project/sherlock/deploy/helpers.py:18: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  feature_cols_dict[feature_set] = pd.read_csv(\n",
      "/mnt/d/GitCode/sherlock-project/sherlock/deploy/helpers.py:18: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  feature_cols_dict[feature_set] = pd.read_csv(\n",
      "/mnt/d/GitCode/sherlock-project/sherlock/deploy/helpers.py:18: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  feature_cols_dict[feature_set] = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "from sherlock.deploy import helpers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "\n",
    "feature_cols = helpers.categorize_features()\n",
    "\n",
    "\n",
    "X_train_char = X_train[feature_cols[\"char\"]]\n",
    "X_train_word = X_train[feature_cols[\"word\"]]\n",
    "X_train_par = X_train[feature_cols[\"par\"]]\n",
    "X_train_rest = X_train[feature_cols[\"rest\"]]\n",
    "X_val_char = X_val[feature_cols[\"char\"]]\n",
    "X_val_word = X_val[feature_cols[\"word\"]]\n",
    "X_val_par = X_val[feature_cols[\"par\"]]\n",
    "X_val_rest = X_val[feature_cols[\"rest\"]]\n",
    "\n",
    "y_train_int = encoder.transform(y_train)\n",
    "y_val_int = encoder.transform(y_val)\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train_int)\n",
    "y_val_cat = tf.keras.utils.to_categorical(y_val_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a73d50ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'dense_10')>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_model_input #960\n",
    "char_model1 #960\n",
    "char_model2 #300\n",
    "char_model3 #300\n",
    "char_model4 #300 kerasTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "503cad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 201), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\")\n"
     ]
    }
   ],
   "source": [
    "#WORD\n",
    "n_weights = 200\n",
    "\n",
    "word_model_input = Input(shape=(word_shape,))\n",
    "word_model1 = BatchNormalization(axis=1)(word_model_input)\n",
    "word_model2 = Dense(\n",
    "    n_weights,\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    ")(word_model1)\n",
    "word_model3 = Dropout(do)(word_model2)\n",
    "word_model4 = Dense(\n",
    "    n_weights,\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    ")(word_model3)\n",
    "\n",
    "print(word_model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "648f3213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 400), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(400,), dtype=tf.float32, name=None), name='tf.__operators__.getitem_3/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='tf.__operators__.getitem_5/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_5'\")\n"
     ]
    }
   ],
   "source": [
    "#PAR\n",
    "n_weights = 400\n",
    "\n",
    "par_model_input = Input(shape=(par_shape,))\n",
    "\n",
    "print(par_model_input)\n",
    "print(par_model_input[0])\n",
    "\n",
    "print(par_model_input[0][0])\n",
    "\n",
    "\n",
    "\n",
    "par_model1 = BatchNormalization(axis=1)(par_model_input)\n",
    "par_model2 = Dense(\n",
    "    n_weights,\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    ")(par_model1)\n",
    "par_model3 = Dropout(do)(par_model2)\n",
    "par_model4 = Dense(\n",
    "    n_weights,\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    ")(par_model3)\n",
    "\n",
    "\n",
    "\n",
    "rest_model_input = Input(shape=(rest_shape,))\n",
    "rest_model1 = BatchNormalization(axis=1)(rest_model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1daeef9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 78), dtype=tf.float32, name=None), name='dense_17/Softmax:0', description=\"created by layer 'dense_17'\")\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 960)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 201)]        0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 960)         3840        ['input_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 201)         804         ['input_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 400)         1600        ['input_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 300)          288300      ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 200)          40400       ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 400)          160400      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 300)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 200)          0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 400)          0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 27)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 300)          90300       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 200)          40200       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 400)          160400      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 27)          108         ['input_8[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 927)          0           ['dense_10[0][0]',               \n",
      "                                                                  'dense_12[0][0]',               \n",
      "                                                                  'dense_14[0][0]',               \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 927)         3708        ['concatenate_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 500)          464000      ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 500)          0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 500)          250500      ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 78)           39078       ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,543,638\n",
      "Trainable params: 1,538,608\n",
      "Non-trainable params: 5,030\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "merged_model1 = concatenate([char_model4, word_model4, par_model4, rest_model1])\n",
    "\n",
    "def _add_main_layers(merged_model1, num_classes):\n",
    "    n_weights = 500\n",
    "\n",
    "    merged_model2 = BatchNormalization(axis=1)(merged_model1)\n",
    "    merged_model3 = Dense(\n",
    "        n_weights,\n",
    "        activation=tf.nn.relu,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    "    )(merged_model2)\n",
    "    merged_model4 = Dropout(do)(merged_model3)\n",
    "    merged_model5 = Dense(\n",
    "        n_weights,\n",
    "        activation=tf.nn.relu,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    "    )(merged_model4)\n",
    "    merged_model_output = Dense(\n",
    "        num_classes,\n",
    "        activation=tf.nn.softmax,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(lamb),\n",
    "    )(merged_model5)\n",
    "\n",
    "    return merged_model_output\n",
    "    \n",
    "    \n",
    "merged_model_output = _add_main_layers(merged_model1, 78) #tensor\n",
    "\n",
    "print(merged_model_output)\n",
    "\n",
    "\n",
    "model = Model(\n",
    "            [char_model_input, word_model_input, par_model_input, rest_model_input],\n",
    "            merged_model_output,\n",
    "        )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53b5cd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 960) dtype=float32 (created by layer 'input_5')>, <KerasTensor: shape=(None, 201) dtype=float32 (created by layer 'input_6')>, <KerasTensor: shape=(None, 400) dtype=float32 (created by layer 'input_7')>, <KerasTensor: shape=(None, 27) dtype=float32 (created by layer 'input_8')>]\n"
     ]
    }
   ],
   "source": [
    "print([char_model_input, word_model_input, par_model_input, rest_model_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e183a7",
   "metadata": {},
   "source": [
    "testing tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d0d4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\"  # local log directory\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a2a7992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunny/miniconda3/envs/env_jax_3/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d75c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b4381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7e98fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610/1610 [==============================] - 38s 22ms/step - loss: 1.6038 - categorical_accuracy: 0.7000 - val_loss: 1.0343 - val_categorical_accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c3be67d60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [\n",
    "        X_train_char.values,\n",
    "        X_train_word.values,\n",
    "        X_train_par.values,\n",
    "        X_train_rest.values,\n",
    "    ],\n",
    "    y_train_cat,\n",
    "    validation_data=(\n",
    "        [\n",
    "            X_val_char.values,\n",
    "            X_val_word.values,\n",
    "            X_val_par.values,\n",
    "            X_val_rest.values,\n",
    "        ],\n",
    "        y_val_cat,\n",
    "    ),\n",
    "    callbacks=[tensorboard_callback],\n",
    "    epochs=1,\n",
    "    batch_size=256,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22a8d8e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11644), started 4 days, 19:20:08 ago. (Use '!kill 11644' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3950f8733a253145\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3950f8733a253145\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(env_jax_3)",
   "language": "python",
   "name": "env_jax_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
