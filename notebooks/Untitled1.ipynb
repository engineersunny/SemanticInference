{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103e55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import zipfile\n",
    "import gdown\n",
    "\n",
    "import statistics as statistics\n",
    "from collections import OrderedDict\n",
    "\n",
    "import string\n",
    "import csv\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sherlock.features.preprocessing import (\n",
    "    extract_features,\n",
    "    convert_string_lists_to_lists,\n",
    "    prepare_feature_extraction,\n",
    "    load_parquet_values,\n",
    ")\n",
    "\n",
    "\n",
    "from sherlock.features.word_embeddings import initialise_word_embeddings\n",
    "from sherlock.functional import extract_features_to_csv\n",
    "from sherlock.features.paragraph_vectors import initialise_pretrained_model, initialise_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing.py\n",
    "\n",
    "\n",
    "from sherlock.features.bag_of_characters import extract_bag_of_characters_features\n",
    "from sherlock.features.bag_of_words import extract_bag_of_words_features\n",
    "from sherlock.features.word_embeddings import extract_word_embeddings_features\n",
    "from sherlock.features.paragraph_vectors import infer_paragraph_embeddings_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24619cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1dff8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## global_state.py\n",
    "\n",
    "_is_first = True\n",
    "\n",
    "\n",
    "def is_first() -> bool:\n",
    "    return _is_first\n",
    "\n",
    "\n",
    "def set_first():\n",
    "    global _is_first\n",
    "    _is_first = False\n",
    "\n",
    "\n",
    "def reset_first():\n",
    "    global _is_first\n",
    "    _is_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e76d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stats_helper.py\n",
    "\n",
    "def compute_stats(values):\n",
    "    _min = min(values)\n",
    "    _max = max(values)\n",
    "    _sum = sum(values)\n",
    "\n",
    "    _mean = np.mean(values)\n",
    "\n",
    "    x = values - _mean\n",
    "\n",
    "    _variance = np.mean(x * x)\n",
    "\n",
    "    if _variance == 0:\n",
    "        _skew = 0\n",
    "        _kurtosis = -3\n",
    "    else:\n",
    "        _skew = np.mean(x ** 3) / _variance ** 1.5\n",
    "        _kurtosis = np.mean(x ** 4) / _variance ** 2 - 3\n",
    "\n",
    "    return _mean, _variance, _skew, _kurtosis, _min, _max, _sum\n",
    "\n",
    "\n",
    "def mode(axis, pre_sorted: bool = False):\n",
    "    if not pre_sorted:\n",
    "        axis = sorted(axis)\n",
    "\n",
    "    _count_max = 1\n",
    "    _count = 0\n",
    "    _mode = _current = axis[0]\n",
    "\n",
    "    for v in axis:\n",
    "        if v == _current:\n",
    "            _count = _count + 1\n",
    "        else:\n",
    "            if _count > _count_max:\n",
    "                _count_max = _count\n",
    "                _mode = _current\n",
    "            _count = 1\n",
    "            _current = v\n",
    "\n",
    "    if _count > _count_max:\n",
    "        return _current\n",
    "\n",
    "    return _mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb00c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpers.py\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/10593387/when-do-i-need-to-escape-characters-within-a-regex-character-set-within\n",
    "\n",
    "# Also include '[' char despite above to prevent the following warning:\n",
    "# .../sherlock-project/sherlock/features/bag_of_characters.py:38: FutureWarning: Possible nested set at position 1\n",
    "#   if search(c, char_set):\n",
    "#\n",
    "# NOTE: Make sure that each item that is escaped has the escaping here. The file may be regenerated using\n",
    "#       generate_chars_col() below.\n",
    "#          sherlock/features/feature_column_identifiers/char_col.tsv\n",
    "def escape_for_regex(c):\n",
    "    if c in ('[', ']', '\\\\', '^', '-'):\n",
    "        return '\\\\' + c\n",
    "    else:\n",
    "        return c\n",
    "\n",
    "\n",
    "# Notes:\n",
    "# 1. form feed ('\\f') is whitespace but was not classed as such in the original paper, hence not present below.\n",
    "# 2. '\\' and '^' are appended to the list to maintain original column sequence\n",
    "CHARACTERS_TO_CHECK = (\n",
    "        [c for c in string.printable if c not in ('\\n', '\\v', '\\r', '\\t', '\\\\', '^')] + ['\\\\', '^']\n",
    ")\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# from sherlock.features.helpers import generate_chars_col\n",
    "# generate_chars_col()\n",
    "def generate_chars_col():\n",
    "    idx = 0\n",
    "    with open(\"../sherlock/features/feature_column_identifiers/char_col.tsv\", \"w\") as char_col:\n",
    "        for c in CHARACTERS_TO_CHECK:\n",
    "            for operation in ('any', 'all', 'mean', 'var', 'min', 'max', 'median', 'sum', 'kurtosis', 'skewness'):\n",
    "                col_header = f'n_{c}-agg-{operation}'\n",
    "\n",
    "                char_col.write(f'{idx}\\t{col_header}\\n')\n",
    "\n",
    "                idx = idx + 1\n",
    "\n",
    "\n",
    "# Alternative for ast.literal_eval, but keeps the elements as str. This version is about 5x faster than literal_eval\n",
    "# in this use case\n",
    "# parse arrays in the form \"['a value', None, 0.89, \\\"other string\\\"]\"\n",
    "def literal_eval_as_str(value, none_value=None):\n",
    "    if value and value[0] == '[' and value[-1] == ']':\n",
    "        value = value[1:-1]\n",
    "\n",
    "    if not value:\n",
    "        return []\n",
    "\n",
    "    strings = []\n",
    "\n",
    "    quote = None\n",
    "    s2 = ''\n",
    "\n",
    "    for s in value.split(', '):\n",
    "        if not s:\n",
    "            strings.append('')\n",
    "        elif s[0] in [\"'\", '\"']:\n",
    "            if len(s) > 1 and s[0] == s[-1]:\n",
    "                strings.append(s[1:-1])\n",
    "            else:\n",
    "                if quote is None:\n",
    "                    quote = s[0]\n",
    "                elif s[0] == quote:\n",
    "                    s2 = s2 + s[1:]\n",
    "                    quote = None\n",
    "                    strings.append(s2 + s[:-1])\n",
    "                    s2 = ''\n",
    "\n",
    "                if len(s) == 1:\n",
    "                    s2 = ', '\n",
    "                else:\n",
    "                    s2 = s2 + s[1:] + ', '\n",
    "        elif quote is not None:\n",
    "            if quote == s[-1]:\n",
    "                quote = None\n",
    "                strings.append(s2 + s[:-1])\n",
    "                s2 = ''\n",
    "            else:\n",
    "                s2 = s2 + s + ', '\n",
    "        elif s == 'None':\n",
    "            strings.append(none_value)\n",
    "        else:\n",
    "            strings.append(s)\n",
    "\n",
    "    return strings\n",
    "\n",
    "\n",
    "def keys_to_csv(keys):\n",
    "    \"\"\"\n",
    "    Encode a list of strings into an Excel CSV compatible header.\n",
    "\n",
    "    Wraps all items with double quotes to prevent legitimate values containing a comma from being interpreted as a\n",
    "    separator, and encodes existing double quotes with two double quotes.\n",
    "    \"\"\"\n",
    "    with io.StringIO() as output:\n",
    "        writer = csv.writer(output, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        writer.writerow(keys)\n",
    "\n",
    "        return output.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bag_of_characters.py\n",
    "\n",
    "\n",
    "# Input: a single column in the form of Python list\n",
    "# Output: ordered dictionary holding bag of character features\n",
    "def extract_bag_of_characters_features(col_values: list, features: OrderedDict):\n",
    "    # Create a set of unique chars from the string vectors to quickly test whether to perform expensive\n",
    "    # processing for any given char\n",
    "    char_set = set(''.join(col_values))\n",
    "\n",
    "    for c in CHARACTERS_TO_CHECK:\n",
    "        value_feature_name = f'n_[{c}]'\n",
    "\n",
    "        if c in char_set:\n",
    "            counts = [s.count(c) for s in col_values]\n",
    "\n",
    "            has_any = any(counts)\n",
    "        else:\n",
    "            has_any = False\n",
    "\n",
    "        if has_any:\n",
    "            _any = 1\n",
    "            _all = 1 if all(counts) else 0\n",
    "            _mean, _variance, _skew, _kurtosis, _min, _max, _sum = compute_stats(counts)\n",
    "            _median = statistics.median(counts)\n",
    "\n",
    "            if is_first():\n",
    "                # the first output needs fully expanded keys (to drive CSV header)\n",
    "                features[value_feature_name + '-agg-any'] = _any\n",
    "                features[value_feature_name + '-agg-all'] = _all\n",
    "                features[value_feature_name + '-agg-mean'] = _mean\n",
    "                features[value_feature_name + '-agg-var'] = _variance\n",
    "                features[value_feature_name + '-agg-min'] = _min\n",
    "                features[value_feature_name + '-agg-max'] = _max\n",
    "                features[value_feature_name + '-agg-median'] = _median\n",
    "                features[value_feature_name + '-agg-sum'] = _sum\n",
    "                features[value_feature_name + '-agg-kurtosis'] = _kurtosis\n",
    "                features[value_feature_name + '-agg-skewness'] = _skew\n",
    "            else:\n",
    "                # subsequent lines only care about values, so we can pre-render a block of CSV. This\n",
    "                # cuts overhead of storing granular values in the features dictionary\n",
    "                features[value_feature_name + '-pre-rendered'] = \\\n",
    "                    f'{_any},{_all},{_mean},{_variance},{_min},{_max},{_median},{_sum},{_kurtosis},{_skew}'\n",
    "        else:\n",
    "            if is_first():\n",
    "                # the first output needs fully expanded keys (to drive CSV header)\n",
    "                features[value_feature_name + '-agg-any'] = 0\n",
    "                features[value_feature_name + '-agg-all'] = 0\n",
    "                features[value_feature_name + '-agg-mean'] = 0\n",
    "                features[value_feature_name + '-agg-var'] = 0\n",
    "                features[value_feature_name + '-agg-min'] = 0\n",
    "                features[value_feature_name + '-agg-max'] = 0\n",
    "                features[value_feature_name + '-agg-median'] = 0\n",
    "                features[value_feature_name + '-agg-sum'] = 0\n",
    "                features[value_feature_name + '-agg-kurtosis'] = -3\n",
    "                features[value_feature_name + '-agg-skewness'] = 0\n",
    "            else:\n",
    "                # assign pre-rendered defaults\n",
    "                features[value_feature_name + '-pre-rendered'] = '0,0,0,0,0,0,0,0,-3,0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f248b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9de14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa3d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a42bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09bd7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    \"\"\"Download raw and preprocessed data files.\n",
    "    The data is downloaded from Google Drive and stored in the 'data/' directory.\n",
    "    \"\"\"\n",
    "    data_dir = \"../data/data/\"\n",
    "    zip_filepath = \"../data/data.zip\"\n",
    "    print(f\"Downloading the raw data into {data_dir}.\")\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(\"Downloading data directory.\")\n",
    "        gdown.download(\n",
    "            url=\"https://drive.google.com/uc?id=1-g0zbKFAXz7zKZc0Dnh74uDBpZCv4YqU\",\n",
    "            output=zip_filepath,\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\"zip extract11\")\n",
    "        with zipfile.ZipFile(zip_filepath, \"r\") as zf:\n",
    "            zf.extractall(data_dir)\n",
    "            print(\"zip extract\")\n",
    "\n",
    "    print(\"Data was downloaded.\")\n",
    "    \n",
    "download_data()\n",
    "prepare_feature_extraction()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Python (env37)]",
   "language": "python",
   "name": "env37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
